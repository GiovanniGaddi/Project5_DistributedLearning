model:
  name: LeNet
  epochs: 150
  batch_size: 64
  learning_rate: 0.005
  loss: CSE
  optimizer: LAMB
  scheduler: CosineAnnealingLR
  patience: 150
  warmup: 0
  weight_decay: 0.0001
  num_workers: 0
experiment:
  name: centralized_lenet
  resume: False
  version: 1.0