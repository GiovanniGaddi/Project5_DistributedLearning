model:
  name: LeNet
  epochs: 150
  batch_size: 64
  learning_rate: 1e-2
  loss: CSE
  optimizer: SGDM
  scheduler: CosineAnnealingLR
  patience: 150
  warmup: 0
  weight_decay: 1e-3
  num_workers: 0
experiment:
  name: centralized_lenet
  resume: False
  version: 1.0